{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "126f09b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "import instructor\n",
    "from litellm import completion\n",
    "\n",
    "from openai import OpenAI\n",
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "\n",
    "import json\n",
    "\n",
    "from typing import List, Dict, Any, Annotated, Optional\n",
    "from operator import add\n",
    "from jinja2 import Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20add0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic Models\n",
    "\n",
    "class ToolCall(BaseModel):\n",
    "    name: str\n",
    "    arguments: dict\n",
    "    server: str\n",
    "\n",
    "# from typing import Optional\n",
    "\n",
    "# class ToolCall(BaseModel):\n",
    "#     name: str\n",
    "#     arguments: dict = Field(alias=\"parameters\")\n",
    "#     server: Optional[str] = None\n",
    "\n",
    "\n",
    "class RAGUsedContext(BaseModel):\n",
    "    id: int\n",
    "    description: str\n",
    "\n",
    "class AgentResponse(BaseModel):\n",
    "    answer: str\n",
    "    tool_calls: List[ToolCall] = Field(default_factory=list)\n",
    "    final_answer: bool = Field(default=False)\n",
    "    retrieved_context_ids: List[RAGUsedContext]\n",
    "\n",
    "class QAAgentResponse(BaseModel):\n",
    "    answer: str\n",
    "    tool_calls: List[ToolCall] = Field(default_factory=list)\n",
    "    final_answer: bool = Field(default=False)\n",
    "    retrieved_context_ids: List[RAGUsedContext]\n",
    "\n",
    "class ClassifierAgentResponse(BaseModel):\n",
    "    answer: str\n",
    "    tool_calls: List[ToolCall] = Field(default_factory=list)\n",
    "    final_answer: bool = Field(default=False)\n",
    "\n",
    "\n",
    "class Delegation(BaseModel):\n",
    "    agent: str\n",
    "    task: str = Field(default=\"\")\n",
    "\n",
    "class CoordinatorAgentResponse(BaseModel):\n",
    "    next_agent: str\n",
    "    plan: list[Delegation]\n",
    "    final_answer: bool = Field(default=False)\n",
    "    answer: str\n",
    "\n",
    "\n",
    "class State(BaseModel):\n",
    "    messages: Annotated[List[Any], add] = []\n",
    "    answer: str = \"\"\n",
    "    iteration: int = Field(default=0)\n",
    "    classifier_iteration: int = Field(default=0)\n",
    "    coordinator_iteration: int = Field(default=0)\n",
    "    job_posting_qa_final_answer: bool = Field(default=False)\n",
    "    classifier_final_answer: bool = Field(default=False)\n",
    "    coordinator_final_answer: bool = Field(default=False)\n",
    "    qa_available_tools: List[Dict[str, Any]] = []\n",
    "    classifier_available_tools: List[Dict[str, Any]] = []\n",
    "    qa_tool_calls: Optional[List[ToolCall]] = Field(default_factory=list)\n",
    "    classifier_tool_calls: Optional[List[ToolCall]] = Field(default_factory=list)\n",
    "    retrieved_context_ids: List[RAGUsedContext] = []\n",
    "    # NEW fields for classifier integration\n",
    "    # retrieved_job_posting: Optional[str] = \"\"            # stores the retrieved job posting text\n",
    "    classification_result: str = \"\"  # store fraud classification result\n",
    "    user_intent: str = \"\"\n",
    "    plan: list[Delegation] = Field(default_factory=list)\n",
    "    next_agent: str = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4018485e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lc_messages_to_regular_messages(msg):\n",
    "\n",
    "    if isinstance(msg, dict):\n",
    "        \n",
    "        if msg.get(\"role\") == \"user\":\n",
    "            return {\"role\": \"user\", \"content\": msg[\"content\"]}\n",
    "        elif msg.get(\"role\") == \"assistant\":\n",
    "            return {\"role\": \"assistant\", \"content\": msg[\"content\"]}\n",
    "        elif msg.get(\"role\") == \"tool\":\n",
    "            return {\n",
    "                \"role\": \"tool\", \n",
    "                \"content\": msg[\"content\"], \n",
    "                \"tool_call_id\": msg.get(\"tool_call_id\")\n",
    "            }\n",
    "        \n",
    "    elif isinstance(msg, AIMessage):\n",
    "\n",
    "        result = {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": msg.content\n",
    "        }\n",
    "        \n",
    "        if hasattr(msg, 'tool_calls') and msg.tool_calls and len(msg.tool_calls) > 0 and not msg.tool_calls[0].get(\"name\").startswith(\"functions.\"):\n",
    "            result[\"tool_calls\"] = [\n",
    "                {\n",
    "                    \"id\": tc[\"id\"],\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\": {\n",
    "                        \"name\": tc[\"name\"].replace(\"functions.\", \"\"),\n",
    "                        \"arguments\": json.dumps(tc[\"args\"])\n",
    "                    }\n",
    "                }\n",
    "                for tc in msg.tool_calls\n",
    "            ]\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    elif isinstance(msg, ToolMessage):\n",
    "\n",
    "        return {\"role\": \"tool\", \"content\": msg.content, \"tool_call_id\": msg.tool_call_id}\n",
    "    \n",
    "    else:\n",
    "\n",
    "        return {\"role\": \"user\", \"content\": str(msg)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2388c28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinator_agent_node(state, models = [\"groq/llama-3.1-8b-instant\",\"gpt-4.1\"]) -> dict:\n",
    "\n",
    "    prompt_template = \"\"\"You are a Coordinator Agent as part of a shopping assistant.\n",
    "\n",
    "Your role is to create plans for solving user queries and delegate the tasks accordingly.\n",
    "You will be given a conversation history, your task is to create a plan for solving the user's query.\n",
    "After the plan is created, you should output the next agent to invoke and the task to be performed by that agent.\n",
    "Once an agent finishes its task, you will be handed the control back, you should then review the conversation history and revise the plan.\n",
    "If there is a sequence of tasks to be performed by a single agent, you should combine them into a single task.\n",
    "\n",
    "The possible agents are:\n",
    "\n",
    "- job_posting_qa_agent: The user is asking a question about a job posting. This can be a question about its specifications, descriptions, text entities etc.\n",
    "- classifier_agent: The user is asking to classifiy job postings on whether the posting is real or not.\n",
    "\n",
    "CRITICAL RULES:\n",
    "- If next_agent is \"\", final_answer MUST be false\n",
    "(You cannot delegate the task to an agent and return to the user in the same response)\n",
    "- If final_answer is true, next_agent MUST be \"\"\n",
    "(You must wait for agent results before returning to user)\n",
    "- If you need to call other agents before answering, set:\n",
    "next_agent=\"...\", final_answer=false\n",
    "- After receiving agent results, you can then set:\n",
    "next_agent=\"\", final_answer=true\n",
    "\n",
    "Additional instructions:\n",
    "\n",
    "- Write the plan to the plan field.\n",
    "- Write the next agent to invoke to the next_agent field.\n",
    "- Once you have all the information needed to answer the user's query, you should set the final_answer field to True and output the answer to the user's query.\n",
    "- The final answer to the user query should be a comprehensive answer that explains the actions that were performed to answer the query.\n",
    "- Never set final_answer to true if the plan is not complete.\n",
    "- You should output the next_agent field as well as the plan field.\n",
    "\"\"\"\n",
    "\n",
    "    prompt = Template(prompt_template).render()\n",
    "\n",
    "    messages = state.messages\n",
    "\n",
    "    conversation = []\n",
    "\n",
    "    for msg in messages:\n",
    "        conversation.append(lc_messages_to_regular_messages(msg))\n",
    "\n",
    "    client = instructor.from_openai(OpenAI())\n",
    "\n",
    "    for model in models:\n",
    "        try:\n",
    "            response, raw_response = client.chat.completions.create_with_completion(\n",
    "                model=model,\n",
    "                response_model=CoordinatorAgentResponse,\n",
    "                messages=[{\"role\": \"system\", \"content\": prompt}, *conversation],\n",
    "                temperature=0,\n",
    "            )\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error with model {model}: {e}\")\n",
    "            continue\n",
    "\n",
    "\n",
    "    if response.final_answer:\n",
    "        ai_message = [AIMessage(\n",
    "            content=response.answer,\n",
    "        )]\n",
    "    else:\n",
    "        ai_message = []\n",
    "\n",
    "    return {\n",
    "        \"messages\": ai_message,\n",
    "        \"answer\": response.answer,\n",
    "        \"next_agent\": response.next_agent,\n",
    "        \"plan\": response.plan,\n",
    "        \"coordinator_final_answer\": response.final_answer,\n",
    "        \"coordinator_iteration\": state.coordinator_iteration + 1,\n",
    "        \"trace_id\": \"\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b70ad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = State(messages=[{\"role\": \"user\", \"content\": \"What is the weather today?\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4f39124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with model groq/llama-3.1-8b-instant: Error code: 400 - {'error': {'message': 'invalid model ID', 'type': 'invalid_request_error', 'param': None, 'code': None}}\n"
     ]
    }
   ],
   "source": [
    "answer = coordinator_agent_node(initial_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93209616",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8da449f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [AIMessage(content=\"I'm sorry, but I can only assist with questions related to job postings, such as their details or authenticity. I am unable to provide weather information.\", additional_kwargs={}, response_metadata={})],\n",
       " 'answer': \"I'm sorry, but I can only assist with questions related to job postings, such as their details or authenticity. I am unable to provide weather information.\",\n",
       " 'next_agent': '',\n",
       " 'plan': [],\n",
       " 'coordinator_final_answer': True,\n",
       " 'coordinator_iteration': 1,\n",
       " 'trace_id': ''}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "216eefee",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinator_eval_dataset = [\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": \"Whats is the weather today?\"}\n",
    "            ]\n",
    "        },\n",
    "        \"outputs\": {\n",
    "            \"next_agent\": \"\",\n",
    "            \"coordinator_final_answer\": True\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": \"What is job 10397 about?\"}\n",
    "            ]\n",
    "        },\n",
    "        \"outputs\": {\n",
    "            \"next_agent\": \"job_posting_qa_agent\",\n",
    "            \"coordinator_final_answer\": False\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": \"Can you classify a posting with ID 10397 and tell me if it's real or fake?\"}\n",
    "            ]\n",
    "        },\n",
    "        \"outputs\": {\n",
    "            \"next_agent\": \"classifier_agent\",\n",
    "            \"coordinator_final_answer\": False\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": \"Can you classify job 123 and also job 456 and tell me if they are real or fake?\"}\n",
    "            ]\n",
    "        },\n",
    "        \"outputs\": {\n",
    "            \"next_agent\": \"classifier_agent\",\n",
    "            \"coordinator_final_answer\": False\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": \"Is job 123 a fraudulent job posting and explain why?\"}\n",
    "            ]\n",
    "        },\n",
    "        \"outputs\": {\n",
    "            \"next_agent\": \"classifier_agent\",\n",
    "            \"coordinator_final_answer\": False\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": \"What of kind things can you classify?\"}\n",
    "            ]\n",
    "        },\n",
    "        \"outputs\": {\n",
    "            \"next_agent\": \"\",\n",
    "            \"coordinator_final_answer\": True\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": \"Can you help me with my request?\"}\n",
    "            ]\n",
    "        },\n",
    "        \"outputs\": {\n",
    "            \"next_agent\": \"\",\n",
    "            \"coordinator_final_answer\": True\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": \"Can you find me 2 suspicious data job postings?\"}\n",
    "            ]\n",
    "        },\n",
    "        \"outputs\": {\n",
    "            \"next_agent\": \"job_posting_qa_agent\",\n",
    "            \"coordinator_final_answer\": False\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": \"Is job 123 related to data analysis?\"}\n",
    "            ]\n",
    "        },\n",
    "        \"outputs\": {\n",
    "            \"next_agent\": \"job_posting_qa_agent\",\n",
    "            \"coordinator_final_answer\": False\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": \"What are the entities that can be extracted from job_id 123?\"}\n",
    "            ]\n",
    "        },\n",
    "        \"outputs\": {\n",
    "            \"next_agent\": \"job_posting_qa_agent\",\n",
    "            \"coordinator_final_answer\": False\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2054a7ec",
   "metadata": {},
   "source": [
    "# Upload dataset to LangSmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b32c1995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "import os\n",
    "\n",
    "client = Client(api_key=os.environ[\"LANGSMITH_API_KEY\"])\n",
    "\n",
    "dataset_name = \"coordinator-evaluation-dataset\"\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"Dataset for evaluating routing of the coordinator agent\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d8985c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in coordinator_eval_dataset:\n",
    "    client.create_example(\n",
    "        dataset_id=dataset.id,\n",
    "        inputs={\"messages\": item[\"inputs\"][\"messages\"]},\n",
    "        outputs={\n",
    "            \"next_agent\": item[\"outputs\"][\"next_agent\"],\n",
    "            \"coordinator_final_answer\": item[\"outputs\"][\"coordinator_final_answer\"]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da35c30b",
   "metadata": {},
   "source": [
    "# Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b9c3c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "import os\n",
    "\n",
    "ls_client = Client(api_key=os.environ[\"LANGSMITH_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b89b5cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_agent_evaluator(run, example):\n",
    "\n",
    "    next_agent_match = run.outputs[\"next_agent\"] == example.outputs[\"next_agent\"]\n",
    "    final_answer_match = run.outputs[\"coordinator_final_answer\"] == example.outputs[\"coordinator_final_answer\"]\n",
    "\n",
    "    return next_agent_match and final_answer_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b074e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ackl/Projects/ai-engineering-bootcamp/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'coordinator-evaluation-dataset-64bbdb1b' at:\n",
      "https://smith.langchain.com/o/cd0c2f03-d905-4ac2-af13-691ee0bcd17d/datasets/fa819a2d-11f0-4086-b60b-2a4165fcf244/compare?selectedSessions=22cbe0f9-93c8-495c-bece-adb2b813727a\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:09,  1.17s/it]\n"
     ]
    }
   ],
   "source": [
    "results = ls_client.evaluate(\n",
    "    lambda x: coordinator_agent_node(State(messages=x[\"messages\"])),\n",
    "    data=\"coordinator-evaluation-dataset\",\n",
    "    evaluators=[\n",
    "        next_agent_evaluator\n",
    "    ],\n",
    "    experiment_prefix=\"coordinator-evaluation-dataset\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8a46583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems like you didn't type anything. Please go ahead and ask your question, and I'll do my best to help. I'm here to provide information and answer your queries to the best of my abilities."
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq()\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    messages=[\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\n",
    "      }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_completion_tokens=1024,\n",
    "    top_p=1,\n",
    "    stream=True,\n",
    "    stop=None\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2a935b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are part of a Analyst Assistant that can classify whether a job posting is real or fake.\\n\\nUser may provide either the full job posting text, job title, or a job ID (job_id). \\n\\nYou will be a conversation history and a list of tools you can use to answer that question.\\n\\n<Available tools>\\n{}\\n</Available tools>\\nIf a job ID or job title is provided, retrieve the corresponding job posting details using `get_formatted_context` tool and extract top result before classification.\\n\\nAfter the tools are used you will get the outputs from the tools.\\n\\nWhen you need to use a tool, format your response as:\\n\\n<tool_call>\\n{\"name\": \"tool_name\", \"arguments\": {...}, \"server\": {...}}\\n</tool_call>\\n\\nUse names specifically provided in the available tools. Don\\'t add any additional text to the names.\\n\\nYou should tend to use tools when additional information is needed to answer the question.\\n\\nIf you set final_answer to True, you should not use any tools.\\n\\n\\nInstructions:\\n- Carefully analyze the provided job details and user input above.\\n- Use up-to-date information about job scams, legitimate job ad characteristics, and known fraud patterns.\\n- Provide a clear verdict: \"Likely Real\", \"Likely Fraudulent\", or \"Uncertain\".\\n- Explain your reasoning with specific evidence from the posting, user input, and retrieved information.\\n- List any red flags or positive signs you identified.\\n- Offer actionable advice to the user.\\n- If the user\\'s request requires using a tool, set tool_calls with the appropriate function name and parameters.\\n- If you have all the information needed to provide a complete answer, set final_answer to True.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "yaml_file = \"../src/api/rag/prompts/classifier_agent.yaml\"\n",
    "prompt_key = 'gpt-4.1'\n",
    "\n",
    "with open(yaml_file, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "template_content = config[\"prompts\"][prompt_key]\n",
    "\n",
    "template = Template(template_content)\n",
    "template.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ce00c77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': {'name': 'job_posting_qa_prompt',\n",
       "  'description': 'This prompt is used for job posting agent.',\n",
       "  'version': '3.0.0'},\n",
       " 'prompts': {'gpt-4.1': 'You are part of a Analyst Assistant. The user is a Fraud Analyst and your job is to answer questions about job postings.\\n\\nYou will be given a question and a list of tools you can use to answer that question.\\n\\n<Available tools>\\n{{ available_tools | tojson }}\\n</Available tools>\\n\\nWhen making tool calls, use this exact format:\\n{\\n    \"name\": \"tool_name\",\\n    \"arguments\": {\\n        \"parameter1\": \"value1\",\\n        \"parameter2\": \"value2\",\\n    },\\n    \"server\": \"server_url\"\\n}\\n\\nCRITICAL: All parameters must go inside the \"arguments\" object, not at the top level of the tool call.\\n\\nExamples:\\n- Get formatted item context:\\n{\\n    \"name\": \"get_formatted_item_context\",\\n    \"arguments\": {\\n        \"query\": \"Kool kids toys.\",\\n        \"top_k\": 5\\n    },\\n    \"server\": \"http://items_mcp_server:8000/mcp\"\\n}\\n\\n- Get formatted user reviews:\\n{\\n    \"name\": \"get_formatted_review_context\",\\n    \"arguments\": {\\n        \"query\": \"Durable.\",\\n        \"item_list\": [\"123\", \"456\"],\\n        \"top_k\": 5\\n    },\\n    \"server\": \"http://reviews_mcp_server:8000/mcp\"\\n}\\n\\nUse names specifically provided in the available tools. Don\\'t add any additional text to the names.\\n\\nYou should tend to use tools when additional information is needed to answer the question.\\n\\nIf you set final_answer to True, you should not use any tools.\\n\\nInstructions:\\n- Carefully analyze the provided job details and user input above.\\n- If a job ID is provided, retrieve the corresponding job posting details using get_formatted_context`before analysis.\\n- You may be asked to extract entities from job postings by using get_formatted_entities tool.\\n- Explain your analysis using retrieved information.\\n- If the user\\'s request requires using a tool, set tool_calls with the appropriate function name and parameters.\\n- If you have all the information needed to provide a complete answer, set final_answer to True.\\n',\n",
       "  'gpt-4.1-mini': 'You are part of a Analyst Assistant. The user is a Fraud Analyst and your job is to answer questions about job postings.\\n\\nYou will be given a question and a list of tools you can use to answer that question.\\n\\n<Available tools>\\n{{ available_tools | tojson }}\\n</Available tools>\\n\\nWhen making tool calls, use this exact format:\\n{\\n    \"name\": \"tool_name\",\\n    \"arguments\": {\\n        \"parameter1\": \"value1\",\\n        \"parameter2\": \"value2\",\\n    },\\n    \"server\": \"server_url\"\\n}\\n\\nCRITICAL: All parameters must go inside the \"arguments\" object, not at the top level of the tool call.\\n\\nExamples:\\n- Get formatted item context:\\n{\\n    \"name\": \"get_formatted_item_context\",\\n    \"arguments\": {\\n        \"query\": \"Kool kids toys.\",\\n        \"top_k\": 5\\n    },\\n    \"server\": \"http://items_mcp_server:8000/mcp\"\\n}\\n\\n- Get formatted user reviews:\\n{\\n    \"name\": \"get_formatted_review_context\",\\n    \"arguments\": {\\n        \"query\": \"Durable.\",\\n        \"item_list\": [\"123\", \"456\"],\\n        \"top_k\": 5\\n    },\\n    \"server\": \"http://reviews_mcp_server:8000/mcp\"\\n}\\n\\nUse names specifically provided in the available tools. Don\\'t add any additional text to the names.\\n\\nYou should tend to use tools when additional information is needed to answer the question.\\n\\nIf you set final_answer to True, you should not use any tools.\\n\\nInstructions:\\n- Carefully analyze the provided job details and user input above.\\n- If a job ID is provided, retrieve the corresponding job posting details using get_formatted_context`before analysis.\\n- You may be asked to extract entities from job postings by using get_formatted_entities tool.\\n- Explain your analysis using retrieved information.\\n- If the user\\'s request requires using a tool, set tool_calls with the appropriate function name and parameters.\\n- If you have all the information needed to provide a complete answer, set final_answer to True.\\n'}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6ddd0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
